<article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">How to configure a laptop's NVIDIA GPU for Deep Learning</h1>
<p class="page-description">Use your own Graphics Card to speed up Tensorflow</p>
<p class="post-meta post-meta-title"><time class="dt-published" datetime="2022-09-12T00:00:00-05:00" itemprop="datePublished">
        Sep 12, 2022
      </time>
       • <span class="read-time" title="Estimated read time">
    
    
      3 min read
    
</span></p>

    
      <p class="category-tags"><i class="fas fa-tags category-tags-icon"></i> 
      
        <a class="category-tags-link" href="/blog/categories/#GPU">GPU</a>
         
      
        <a class="category-tags-link" href="/blog/categories/#tensorflow">tensorflow</a>
         
      
        <a class="category-tags-link" href="/blog/categories/#torch">torch</a>
        
      
      </p>
    

    
      
        <div class="pb-5 d-flex flex-justify-center">
          <div class="px-2">

    <a href="https://github.com/alvaroof/blog/tree/master/_notebooks/2022-09-12-using_cuda.ipynb" role="button" target="_blank">
<img class="notebook-badge-image" src="/blog/assets/badges/github.svg" alt="View On GitHub">
    </a>
</div>

          <div class="px-2">
    <a href="https://mybinder.org/v2/gh/alvaroof/blog/master?filepath=_notebooks%2F2022-09-12-using_cuda.ipynb" target="_blank">
        <img class="notebook-badge-image" src="/blog/assets/badges/binder.svg" alt="Open In Binder">
    </a>
</div>

          <div class="px-2">
    <a href="https://colab.research.google.com/github/alvaroof/blog/blob/master/_notebooks/2022-09-12-using_cuda.ipynb" target="_blank">
        <img class="notebook-badge-image" src="/blog/assets/badges/colab.svg" alt="Open In Colab">
    </a>
</div>
          
        </div>
      </header>

  <div class="post-content e-content" itemprop="articleBody">
    <ul id="toc" class="section-nav">
<li class="toc-entry toc-h1"><a href="#Introduction">Introduction </a></li>
<li class="toc-entry toc-h1"><a href="#Let's-Get-to-it">Let's Get to it </a></li>
<li class="toc-entry toc-h1"><a href="#Check-Configuration">Check Configuration </a></li>
<li class="toc-entry toc-h1"><a href="#References">References </a></li>
</ul>
<!--
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: _notebooks/2022-09-12-using_cuda.ipynb
-->

<div class="container" id="notebook-container">
        
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Introduction">
<a class="anchor" href="#Introduction" aria-hidden="true"><span class="octicon octicon-link"></span></a>Introduction<a class="anchor-link" href="#Introduction"> </a>
</h1>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>It is well known for anybody who has ever tried to train any Deep Learning model beyond a simple Multi Layer Perceptron on a few observations that using a GPU for training is kind of a must. While nowadays many different platforms and services offer GPUs for free (I'm looking at you Kaggle and Google Colab) if you're anything like me, and you also happen to have a good NVIDIA Graphics Card in your computer, surely you've felt like giving it a go by yourself.</p>
<p>And here is where complications start. Configuring a NVIDIA GPU to be found by your favourite Deep Learning framework it's way more complicated than it should. Specially if you are installing it on Windows, as it happens to me. Chances are that you have not purchased a high-end NVIDIA exclusively for doing Deep Learning, bur rather you bought the laptop as a gaming station (this is basically what happened to me) and thought of exploring the GPU capabilities in it.</p>
<p>I've gone through the process a few times, and what follows it's my own personal guidelines to replicate the setup should I have to do a hard reset on my laptop (God forbids),</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Let's-Get-to-it">
<a class="anchor" href="#Let's-Get-to-it" aria-hidden="true"><span class="octicon octicon-link"></span></a>Let's Get to it<a class="anchor-link" href="#Let's-Get-to-it"> </a>
</h1>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Basically we need to install a few things, and the bigger complexity comes from knowing what these are, and which version we should get.</p>
<p>First of all, we are going to download the <a href="https://www.nvidia.es/Download/index.aspx">latest driver</a> for Our NVIDIA Card. In my case, it's a RTX 2060 operating on Windows 11. For this one you would want to have the latest one. For things we will be installing afterwwards that won't be the case, as we will have contraints due to for example, which version of CUDA is allowed for our card model.</p>
<p>Another thing you would need is the latest <strong>Microsoft Visual C++</strong> development kit.</p>
<p>Install <a href="https://developer.nvidia.com/cuda-downloads">CUDA toolkit 11</a> at least, and certainly the latest one available.</p>
<p>We will also need <strong>cuDNN</strong>. Here we differ from the guidelines offered by Professor Heaton in the tutorial in the references section. Reason is, if we are willing to go with versions that are not precisely the latest ones for Tensorflow or other frameworks, then we can let <strong>conda</strong> take care of the installation of the rest of pieces. We will use conda to create a brand new environment containing a version of cudnn and cudatoolkit that our Graphics Card would tolerate, and finally a good combination of python version and tensorflow version.</p>
<p>In my case this happens to be:</p>
<div class="highlight"><pre><span></span>conda create -n tensorflow-cuda <span class="nv">cudnn</span><span class="o">=</span><span class="m">7</span>.6 <span class="nv">cudatoolkit</span><span class="o">=</span><span class="m">11</span>.1 <span class="nv">python</span><span class="o">=</span><span class="m">3</span>.7
conda activate tensorflow-cuda
conda install nb_conda
pip install <span class="nv">tensorflow</span><span class="o">==</span><span class="m">2</span>.3.0
conda env update --file environment.yml
python -m ipykernel install --user --name tensorflow-cuda --display-name <span class="s2">"Python (tensorflow-cuda)"</span>
</pre></div>
<p>I typically use <code>environment.yml</code> as a mean to install any additional library I may need and update the environment on the fly each time. Say I need or want to use scikitlearn and it wasn't installed, I just add it to the <code>environment.yml</code> file and update the environment.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Check-Configuration">
<a class="anchor" href="#Check-Configuration" aria-hidden="true"><span class="octicon octicon-link"></span></a>Check Configuration<a class="anchor-link" href="#Check-Configuration"> </a>
</h1>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>After this, we can quickly test whether our installation of Tensorflow is working appropiately. I will use the jupyter kernel running behind this post as it is easy and convenient for me. A simple matrix multiplication will do. I mean, that's <strong>why we use GPUs to begin with</strong>.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>

<span class="nb">print</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">test</span><span class="o">.</span><span class="n">is_gpu_available</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">test</span><span class="o">.</span><span class="n">is_built_with_cuda</span><span class="p">())</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>WARNING:tensorflow:From C:\Users\alvaroof\AppData\Local\Temp\ipykernel_14080\712885346.py:3: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.config.list_physical_devices('GPU')` instead.
True
True
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>If I switch to the jupyter kernel without GPU enabled:</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">%%time</span>

<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="kn">import</span> <span class="nn">warnings</span>
<span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s1">'ignore'</span><span class="p">)</span>

<span class="n">tf</span><span class="o">.</span><span class="n">debugging</span><span class="o">.</span><span class="n">set_log_device_placement</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span> 
<span class="n">a</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">([</span><span class="mf">1.22582</span><span class="p">],</span> <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="mi">10000</span><span class="p">,</span> <span class="mi">10000</span><span class="p">],</span> <span class="n">name</span><span class="o">=</span><span class="s1">'a'</span><span class="p">)</span>
<span class="n">b</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">([</span><span class="mf">1.1125</span><span class="p">],</span> <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="mi">10000</span><span class="p">,</span> <span class="mi">10000</span><span class="p">],</span> <span class="n">name</span><span class="o">=</span><span class="s1">'b'</span><span class="p">)</span>
<span class="n">c</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Executing op Fill in device /job:localhost/replica:0/task:0/device:CPU:0
Executing op Fill in device /job:localhost/replica:0/task:0/device:CPU:0
Executing op MatMul in device /job:localhost/replica:0/task:0/device:CPU:0
Wall time: 6.45 s
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>And with GPU</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">%%time</span>

<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="kn">import</span> <span class="nn">warnings</span>
<span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s1">'ignore'</span><span class="p">)</span>

<span class="n">tf</span><span class="o">.</span><span class="n">debugging</span><span class="o">.</span><span class="n">set_log_device_placement</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span> 
<span class="n">a</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">([</span><span class="mf">1.22582</span><span class="p">],</span> <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="mi">10000</span><span class="p">,</span> <span class="mi">10000</span><span class="p">],</span> <span class="n">name</span><span class="o">=</span><span class="s1">'a'</span><span class="p">)</span>
<span class="n">b</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">([</span><span class="mf">1.1125</span><span class="p">],</span> <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="mi">10000</span><span class="p">,</span> <span class="mi">10000</span><span class="p">],</span> <span class="n">name</span><span class="o">=</span><span class="s1">'b'</span><span class="p">)</span>
<span class="n">c</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Executing op Fill in device /job:localhost/replica:0/task:0/device:GPU:0
Executing op Fill in device /job:localhost/replica:0/task:0/device:GPU:0
Executing op MatMul in device /job:localhost/replica:0/task:0/device:GPU:0
Wall time: 608 ms
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>As we can see, with GPU the matrix multiplication takes 10x less time to run <img class="emoji" title=":smiley:" alt=":smiley:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f603.png" height="20" width="20">.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="References">
<a class="anchor" href="#References" aria-hidden="true"><span class="octicon octicon-link"></span></a>References<a class="anchor-link" href="#References"> </a>
</h1>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li><a href="https://www.tensorflow.org/install/gpu">Tensorflow Documentation</a></li>
<li><a href="https://www.youtube.com/watch?v=OEFKlRSd8Ic">Jeff Heaton's Video Tutorial</a></li>
</ul>

</div>
</div>
</div>
</div>



  </div>
<!-- from https://github.com/utterance/utterances -->
<script src="https://utteranc.es/client.js" repo="alvaroof/blog" issue-term="title" label="blogpost-comment" theme="github-light" crossorigin="anonymous" async>
</script><a class="u-url" href="/blog/gpu/tensorflow/torch/2022/09/12/using_cuda.html" hidden></a>
</article>
